{"/about":{"title":"About","data":{"":"nothing here for now :)"}},"/deployment":{"title":"Deployment","data":{"initial-deployment#Initial Deployment":"Returning to the foundational concepts on the first pages, Kubernetes serves as an open-source system designed for the automation of deployment, scaling, and management of containerized applications.To configure Kubernetes to reflect the desired state, we interact with the Kubernetes API, which exposes various \"domains\" within the platform, referred to as \"kinds.\" Here are some examples:\nDeployment\nService\nPod\nNamespace\nConfigMap\nIngresses\nSecrets\nCronJobs\nYou can retrieve the entire list of resources using the command kubectl api-resources, where the first column represents the resource name and the last column indicates the corresponding \"kind\".In most cases, we utilize the kubectl command-line interface (CLI) to access the API, passing YAML files as the data format (although JSON can also be used, YAML is more commonly used within the community).Back to the desired state, this is the key to understand the Deployment kind. Within a deployment, we configure our entire application, specifying parameters such as the number of replicas, resource utilization, environment variables, volumes, name, port, and, most importantly, the image (including it's version) to deploy.For official Kubernetes documentation on Deployment concepts, refer to this link, and for the API documentation, visit here.","first-deployment-file#First deployment file":"Here we have a simple deployment file (also available in the examples/deployment directory):\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deployment\n  labels:\n    app: nginx\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.14.2\n        env:\n        - name: ENV1\n          value: \"value1\"\n        - name: ENV2\n          value: \"value2\"\n        ports:\n        - containerPort: 80\nFirstly, we define the API version (although there isn't much choice here, so we can overlook it for now).\nWe specify the kind of file, which is a deployment. Consequently, everything needs to respect the API documentation.\nIn the metadata field, we assign the application name and one label. Although the label may not be directly relevant to the system, it proves useful for filtering and querying information in the future (e.g., kubectl get pods -l app=nginx).\nThe spec section contains the most critical components:\n4.1 We set the number of replicas to 3, resulting in the creation of 3 Pods for the application (refer to the Pod page for details).\n4.2 The selector field is crucial for connecting our deployment with other kinds, such as the \"service\" kind, in the future.\n4.3 Within the template field, we define the pod's specifications. Each pod will follow to this template definition, including:\n4.3.1 Additional labels are added for easier filtering in the future. It's important to note that Kubernetes validates if the selector labels match the template labels; otherwise, the deployment will fail.\n4.3.2 In the template.spec section, we define the container(s) with their name, image, version, and container port.\n4.3.3 We also include some environment variables (in the future, we may add variables from secrets as well).\nOne quick tip here, most of the times the basic deployement file with secrets will be good enough for the majority of apps, but if you need anything else, there is a lot of examples available in the internet, so basically get the example and change the value following your needs.Some action now!Let's take some action now!\nNavigate to the examples/deployment directory in the root of this project.\nUse the command ls to confirm the presence of the deployment.yaml file.\nExecute kubectl apply -f deployment.yaml. The result should indicate: \"deployment.apps/nginx-deployment created\".\nRun kubectl get pods. The output might initially show the status as \"creating\" or \"pending\". Wait momentarily and re-run the command.\nnginx-deployment-7db45ddcff-44rhk   1/1     Running   0          20s\nnginx-deployment-7db45ddcff-dtl82   1/1     Running   0          20s\nnginx-deployment-7db45ddcff-lw4jz   1/1     Running   0          20s\nNow, this example NGINX is up and running inside Kubernetes!\nTo access it locally, initiate a port-forward. First, re-run kubectl get pods and copy one of the pod names.\nThen, execute kubectl port-forward nginx-pod-name 3000:80.\nOpen your browser and navigate to localhost:3000 to view NGINX."}},"/deployment/update":{"title":"Deployment - Update","data":{"":"This page dive into the process of updating deployments in Kubernetes.Imagine you're creating a pipeline to continuously deploy or update your application. Typically, only the Docker image version changes between deployments. How does Kubernetes manage these updates?During the initial deployment, Kubernetes creates the required resources, such as pods, which are then started and transitioned to a running state. However, when you modify the deployment configuration, either through the API or CLI, Kubernetes detects this change and seeks to align the actual state with the desired state.Consider the scenario where you apply the same YAML configuration used in the previous deployment but with a different Docker image version:\nCheck for Existing Deployment: Begin by verifying the presence of the previous NGINX deployment using kubectl get deployments. If it's not found, apply the YAML file from the examples/deployment directory.\nApply Updated Configuration: Apply the modified YAML file from the examples/updated-deployment folder. The output should be \"deployment.apps/nginx-deployment configured\"\nUpdate Process: Kubernetes initiates the update process by first launching pods for the new deployment. It then verifies if these pods initialize successfully. If successful, Kubernetes terminates the old pods and replaces them with the new ones. However, if initialization fails for any new pods, the old pods remain active, also the new one (with error) to allow the debugging of the issue.\nHandling Corner Cases: It's worth noting that while Kubernetes automatically restarts pods when the deployment configuration changes, the same doesn't apply to secondary resources like config maps and secrets. In such cases, manual pod restarts or custom solutions may be necessary."}},"/docker":{"title":"Docker first image","data":{"":"The first step to using Kubernetes is to understand how containerized applications work and how to create them, because kubernetes is an open-source system for automating deployment, scaling, and management of containerized applications.In this step, we will quickly create a test application and build a Docker image of it. Later, we will run this application to see firsthand what we are doing.","first-dockerfile#First Dockerfile":"Today, most backend applications include a Dockerfile in their repository. This practice simplifies local testing across different machines (with multiple developers) and establishes an automated environment. It mitigates the need for complex application setups and eliminates dependencies on specific operating systems.Each application will have unique requirements in its Dockerfile. Here are some examples:\nBase Image: Defining the base image for the Docker container, such as FROM python:3.9 for a Python application or FROM node:14 for a Node.js application.\nOS packages: Some applications require specific OS packages to run properly. So, in the Dockerfile, we install these packages to create the necessary environment.\nContainer Startup Command: Specifying the command to run when the container starts, typically using the CMD instruction to execute the application or a script.\nNow, to keep it simple, let's create a Dockerfile for our test application that doesn't require any complex setup.In the repository of this application, we have a folder called 'examples.' Navigate to the 'examples/docker' directory, where you will find the following files:\nindex.js\npackage.json\nDockerfile\nThe index.js file contains only a getting started of a fastify server, the package.json contains only the fastify dependency and the Dockerfile contains only the basic to install the dependencies and start the app.Now let's focus exclusively on the Dockerfile.\nFROM node:20\nWORKDIR /app\nCOPY package.json package.json\nCOPY package-lock.json package-lock.json\nRUN npm ci\nCOPY ./index.js .\nCMD [ \"node\", \"index.js\" ]\nThe first line is responsible for defining what type of image will be built on, almost as if we choose which OS our app will run on.In this example, we're utilizing a base image of Node.js version 20. This image is built on Debian's Bullseye version. If you're curious about the definition of a Docker base image, you can always refer to the Docker website or the official Node.js Dockerfile.The second line sets the working directory to '/app' to prevent errors or misplacements, ensuring that all subsequent commands execute within this directory.The third and fourth lines copy the application's dependency files into the container. Subsequently, the fifth line runs 'npm ci', which installs only the necessary dependencies without dev dependencies. While we could also copy 'node_modules', 'npm ci' is preferred for minimizing the image size by excluding unnecessary dependencies.The sixth line copies our application into the image, while the last line executes the command to start our app.","extra-comments#Extra Comments:":"Multiple Steps for Production Environments: In production environments, consider using multiple steps in the Dockerfile. This approach results in smaller and less vulnerable images. More information can be found here.\nHandling Private npm Registries: Companies often use private npm registries to store npm packages. Additional steps may be required to handle npm authentication. For npm registries from npm itself, refer to this guide. For private registries from other sources (e.g., Azure), utilize the .npmrc file and the NPM_TOKEN environment variable for critical information. Learn how to create the .npmrc file here and how to use it inside the Dockerfile here.\nCustom Entrypoint: The entrypoint can be simple or anything that your need/want. For instance, if your app requires running a script before startup, this is the place to define it.","building-the-image#Building the Image":"With everything in place, let's build our image and run it locally for testing. First, ensure that Docker is installed and running on your system.To build the image, follow these steps:\nOpen your terminal and navigate to the 'examples/docker' folder.\nRun ls to confirm that you are inside the 'examples/docker' folder.\nRun the command:\ndocker build -t somename/backend-00 .\nThis command builds the image. The name 'somename/backend-00' is arbitrary for now but will become important in the future. Don't forget to include the dot at the end of the command.\nAfter successful build, you should see a message like \"naming to docker.io/somename/backend-00\". This indicates that the image is now available in your local Docker registry. You can verify this by running:\ndocker images\nNow, run the app using the command:\ndocker run -d -p 3000:3000 somename/backend-00\nThe -d flag runs the container in detach mode, docker will start your container and return you to the terminal prompt.\nThe -p 3000:3000 flag binds port 3000 of the container to TCP port 3000 on 127.0.0.1 of the host. More information here.\nReplace somename/backend-00 with the image name. You can specify a version like somename/backend-00:v1.\nTo view the logs of the container, use:\ndocker ps to list all running containers and get the container id.\ndocker logs <container_id> to view logs.\ndocker logs -f <container_id> to follow the logs continuously.\nTo stop the container:\ndocker ps to list all running containers.\ndocker stop <container_id> or docker kill <container_id>. The former stops the container gracefully, while the latter kills the process immediately.\nNow you're ready to move on to the next step! ðŸ˜Š"}},"/":{"title":"Kubernetes starting guide","data":{"":"Welcome to the introductory Kubernetes course for developers. Our goal is to create a step-by-step guide that facilitates the adaptation to this new environment.Each page will guide you through a Kubernetes feature, providing a brief explanation of the concepts, followed by examples that can be replicated on your machine.","requirements#Requirements":"Next, the list of all the packages that need to be installed beforehand:\nDocker\nkind\nkubectl","lets-start#Let's start!":"Here is list of pages currently available, the ideal path is to follow step by step, but if you already feel comfortable with one of the concepts, feel free to skip to the next one!\nDocker first image\nKind\nPod\nDeployment\nService"}},"/kind":{"title":"Setting Up Your Playground","data":{"":"Before diving into Kubernetes concepts, let's make sure we have all the prerequisites in place, as mentioned in the last step. Here's the list of requirements again.","requirements#Requirements:":"Docker\nkind\nkubectl\nYou can start by playing with the kind quick start if you'd like, but it's not necessary. Just make sure the package is installed and ready to create and delete clusters.To emulate a cloud scenario, we'll not only create the cluster but also set up a private registry to \"push\" test images.This is necessary because the cluster created won't be able to access images from your local Docker, and to avoid using a real registry, we'll create a private one locally to emulate this behavior.In the setup folder, you'll find the file \"kind-with-registry.sh\", which does the following:\nChecks if your local Docker already has a running container of the registry image, essentially a local Docker image registry to avoid pushing your testing images to real registries.\nCreates the kind cluster with a custom configuration to utilize the previously created registry.\nAdds the registry configuration for every created node.\nConnects the registry image and the kind image to the same network.\nYou can refer to the comments in the file to understand more about the commands, and here is the source.Now you're ready to move on to the next step!OBS: if you are using windows, use the ps1 file :)"}},"/pod":{"title":"Pods in Kubernetes","data":{"":"Kubernetes (k8s) is an open-source system for automating deployment, scaling, and management of containerized applications. A Kubernetes pod is the smallest unit of a Kubernetes application, representing one or more LinuxÂ® containers.In Kubernetes, the running pod often represents the final outcome of various configurations and setups. Whether you're creating secrets, environment variables, or volumes, all these components are utilized by the pod to execute the desired processes.For more detailed information about pod concepts, you can explore resources from Red Hat's documentation or refer to the official Kubernetes documentation.","preparations#Preparations":"Before we start, let's ensure that all necessary components are properly set up:\nConfirm that kind get clusters command returns \"kind\".\nVerify that kubectl get ns command returns the following namespaces:\ndefault              Active   85s\nkube-node-lease      Active   85s\nkube-public          Active   85s\nkube-system          Active   85s\nlocal-path-storage   Active   81s\nEnsure that docker ps command returns containers similar to:\nea8a03090f38   kindest/node:v1.29.2   \nfd02087d52ea   registry:2\nIf only the kubectl step is failing, you can try the following steps:\nRun kubectl config get-contexts and verify that it returns a list. Search for \"kind-kind\" within the list.\nIf \"kind-kind\" context is not found, set the correct context using:\nkubectl config set-context kind-kind\nOnce the correct context is set, retry the command:\nkubectl get ns\nLet's refine the explanation of the basic Pod YAML:\napiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx\nspec:\n  containers:\n  - name: nginx\n    image: nginx:1.14.2\n    ports:\n    - containerPort: 80\nThis YAML file starts a Pod in Kubernetes with an Nginx server without any customizations. Here's a breakdown of what it includes:\napiVersion: Specifies the version of the Kubernetes API being used. In this case, the Pod is part of the \"v1\" API version. You can check supported resources and API versions by running kubectl api-resources.\nkind: Identifies the type of Kubernetes object being created or managed. Here, we're creating a Pod.\nmetadata: Contains organizational and informational details about the Kubernetes object, such as its name, namespace (which we'll explore in the future), labels, etc. You can learn more about metadata here.\nspec.containers: Defines the containers to be run within the Pod. Each entry in this list represents a separate container. In this example, we have:\nThe name of the container.\nThe Docker image to be used for the container.\nThe port exposed by the container.\nFor more detailed documentation on each field that can be modified or added within the spec field of a Pod API, refer to PodSpec. You can also consider this API as configuring the entire environment for your application. Whenever your application requires specific configurations, you can consult this API to find where to add them. (Additional examples are provided at the end.)","your-first-pod#Your first pod!":"In the examples/pod folder, you'll find the nginx.yaml file. Let's apply it into our local Kubernetes environment.Assuming all prerequisites are in place, follow these steps:\nNavigate to the examples/pod directory from the root of this project.\nUse the command ls to confirm the presence of the nginx.yaml file.\nExecute kubectl apply -f nginx.yaml. The result should display: \"pod/nginx created\".\nRun kubectl get pods. The output might initially show the status as \"creating\" or \"pending\". Wait momentarily and re-run the command.\nnginx                         1/1     Running   0          13s\nThe NGINX container is now operational within Kubernetes!\nTo access it locally, execute a port-forward with kubectl port-forward nginx 3000:80.\nOpen your browser and navigate to localhost:3000 to access the NGINX server.\nIf needed, delete the pod using kubectl delete pod nginx.\nRe-run kubectl get pods to confirm the deletion of the nginx pod.","examples#Examples":"Here are some examples of pod configurations, provided here as a reference. However, in a real usage, always check if there are any additional steps outlined in the documentation.","pod-with-environment-variables#Pod with environment variables":"apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx\nspec:\n  containers:\n  - name: nginx\n    image: nginx:1.14.2\n    env:\n      - name: ENV1\n        value: \"value1\"\n      - name: ENV2\n        value: \"value2\"\n    ports:\n    - containerPort: 80","pod-with-environment-variables-from-secrets#Pod with environment variables from secrets":"apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx\nspec:\n  containers:\n  - name: nginx\n    image: nginx:1.14.2\n    env:\n      - name: ENV_FROM_SECRETS\n        valueFrom:\n          secretKeyRef:\n            name: mysqlpwd\n            key: password\n    ports:\n    - containerPort: 80","pod-with-resources-limits#Pod with resources limits":"apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx\nspec:\n  containers:\n  - name: nginx\n    image: nginx:1.14.2\n    resources:\n      requests:\n        memory: \"64Mi\"\n        cpu: \"250m\"\n      limits:\n        memory: \"128Mi\"\n        cpu: \"500m\"\n    ports:\n    - containerPort: 80","pod-with-poststart-and-prestop-hooks#Pod with postStart and preStop hooks":"apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx\nspec:\n  containers:\n  - name: nginx\n    image: nginx:1.14.2\n    lifecycle:\n      postStart:\n        exec:\n          command: [\"/bin/sh\", \"-c\", \"echo Hello from the postStart handler > /usr/share/message\"]\n      preStop:\n        exec:\n          command: [\"/bin/sh\",\"-c\",\"nginx -s quit; while killall -0 nginx; do sleep 1; done\"]\n    ports:\n    - containerPort: 80","pod-with-initcontainer-to-check-if-the-database-is-up#Pod with initContainer to check if the Database is up":"apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx\nspec:\n  containers:\n  - name: nginx\n    image: nginx:1.14.2\n    lifecycle:\n      postStart:\n        exec:\n          command: [\"/bin/sh\", \"-c\", \"echo Hello from the postStart handler > /usr/share/message\"]\n      preStop:\n        exec:\n          command: [\"/bin/sh\",\"-c\",\"nginx -s quit; while killall -0 nginx; do sleep 1; done\"]\n    ports:\n    - containerPort: 80\n  - name: init-mydb\n    image: busybox:1.28\n    command: ['sh', '-c', \"until nslookup mydb.host.com; do echo waiting for mydb; sleep 2; done\"]"}},"/service":{"title":"Service - Introduction","data":{"":"In Kubernetes, a Service is an abstraction that defines a logical set of Pods and a policy by which to access them. It provides a stable endpoint (usually an IP address and port) to interact with a group of Pods serving the same application.","why-use-services#Why Use Services?":"Let's imagine the following scenario: you've deployed the application, the pod is already running, and everything is working. You grab the IP address of that specific pod and use it as an environment variable for another application. In this case, everything will work smoothly, and the second application will be able to access it without any issues.Now imagine that you've updated your application's version and the old pods were deleted while the new ones took their place. That IP address you obtained earlier no longer exists, and you need to update the second application again. You can see the problem, right? That's why the service was designed for.When Pods are created in Kubernetes, they are ephemeral and can be terminated or replaced at any time. Services provide a way to decouple the access to Pods from their underlying network configuration. They ensure that clients can reliably access the application running inside Pods, regardless of changes in the Pod's IP addresses or scheduling.Let's try to replicate this issue together, first in the folder examples/curl you will have the following file:\napiVersion: v1\nkind: Pod\nmetadata:\n  name: curl-pod\nspec:\n  containers:\n  - name: curl-container\n    image: alpine:latest\n    command: [\"/bin/sh\", \"-c\"]\n    args:\n    - \"apk add --no-cache curl && sleep infinity\"\nIt starts an \"empty\" pod with Linux so that we can use it as a fake secondary application. Let's go through the steps:\nFirst, run kubectl apply -f examples/curl/alpine.yaml to create the pod with Linux.\nNow, let's use a new command that allows us to run commands inside a specific pod:\nkubectl exec -it curl-pod -- sh, this command will open a terminal session for you inside the chosen pod, in this case, the pod with Linux.\nInside this terminal, try running curl just to verify if the command exists.\nNow, in another terminal tab of your machine, run kubectl get pods to check if the nginx pods are there. If they are not, run kubectl apply -f examples/deployment/nginx.yaml to create them again.\nRun kubectl get pods again and choose one of the nginx pods, for example:\n    curl-pod                            1/1     Running   0          6m28s\n    // I'll choose this one below\n    nginx-deployment-7db45ddcff-29qvz   1/1     Running   0          24s\n    nginx-deployment-7db45ddcff-4skkl   1/1     Running   0          24s\n    nginx-deployment-7db45ddcff-lmx5b   1/1     Running   0          24s\nNow, to find out the IP of the chosen pod, run kubectl describe pod <chosen-pod-name>. The result will be something similar to the one below, with some information removed to reduce size:\n    Name:             nginx-deployment-7db45ddcff-29qvz\n    Namespace:        default\n    Priority:         0\n    Service Account:  default\n    Node:             kind-control-plane/172.18.0.2\n    Start Time:       Thu, 18 Apr 2024 15:52:44 -0300\n    Labels:           app=nginx\n                    pod-template-hash=7db45ddcff\n    Annotations:      <none>\n    Status:           Running\n    // Here's the IP!!!\n    IP:               10.244.0.6\n    IPs:\n    IP:           10.244.0.6\n    Controlled By:  ReplicaSet/nginx-deployment-7db45ddcff\nNow, go back to the terminal from step 2 and run curl <nginx-pod-ip>, and the response will be an HTML from nginx! That means we successfully accessed the other pod.\nBack to the terminal of your machine, run kubectl delete pod -l app=nginx to delete the pods from the nginx deployment, following what we learned on the deployment page, the pods will restart. To see the new pods, run kubectl get pods.\nIn the terminal created in step 2, run the same command curl <nginx-pod-ip> as in step 7 without changing the IP, and the request will fail because the IP was changed when creating the new pods.","solving-the-problem#Solving the problem":"Let's create a simple NGINX Service:\napiVersion: v1\nkind: Service\nmetadata:\n  name: nginx-service\nspec:\n  selector:\n    app: nginx\n  ports:\n    - protocol: TCP\n      port: 80\n      targetPort: 80\n  type: ClusterIP\nIn this example:\nmetadata.name: Specifies the name of the Service.\nspec.selector: Defines the Pods that the Service will target based on their labels. In this case, it selects Pods labeled with app: nginx.\nspec.ports: Specifies the port configuration. It exposes port 80 on the Service, which forwards traffic to port 80 on the targeted Pods.\nspec.type: Sets the type of the Service to ClusterIP.\nRun kubectl apply -f examples/services/nginx.yaml to create the service.\nIf you have deleted the pod with Linux (curl-pod), recreate it with kubectl apply -f examples/curl/alpine.yaml.\nRun kubectl exec -it curl-pod -- sh to recreate the terminal if you have closed it.\nNow execute curl nginx-service and see that the response with the HTML is returned normally.\nIn a separate terminal on your machine, delete all pods again with kubectl delete pod -l app=nginx and wait for the new ones to start.\nRun step 4 again and you will see that the request still works, we're done! we no longer need to worry about the automatically generated IP.","types-of-services#Types of Services":"Kubernetes supports various types of Services, each with different networking characteristics:\nClusterIP: Exposes the Service on an internal IP within the cluster. This type makes the Service accessible only from within the cluster. It is the default type.\nNodePort: Exposes the Service on a port on each node in the cluster. This type makes the Service accessible externally using the node's IP address and the specified port.\nLoadBalancer: Creates an external load balancer in the cloud provider's network that forwards traffic to the Service. This type is mainly used when running Kubernetes in a cloud environment that supports external load balancers.\nExternalName: Maps the Service to the contents of the externalName field. This type allows you to reference external services by name."}}}